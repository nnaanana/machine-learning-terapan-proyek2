# -*- coding: utf-8 -*-
"""ML-Terapan 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wAGZpBSFgX5Ck-SPQE8SonGbUGcvTbwz

# Proyek Kedua Machine Learning Terapan - Recommendation System
- **Nama:** Nabilah Wanara
- **Email:** 	mc006d5x211p@student.devacademy.id
- **ID Dicoding:** MC006D5X2119

# Import Library dan Setup
"""

import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from scipy.sparse import csr_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

import warnings
warnings.filterwarnings('ignore')

from google.colab import files
files.upload()

os.makedirs('/root/.kaggle', exist_ok=True)
!cp kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

"""# Data Loading"""

#Download dataset dari Kaggle
!kaggle datasets download -d meirnizri/cellphones-recommendations

!unzip -q cellphones-recommendations.zip -d cellphones-recommendations

def load_data(folder_path):
    data_file = os.path.join(folder_path, 'cellphones data.csv')
    users_file = os.path.join(folder_path, 'cellphones users.csv')
    ratings_file = os.path.join(folder_path, 'cellphones ratings.csv')

    products = pd.read_csv(data_file)
    users = pd.read_csv(users_file)
    ratings = pd.read_csv(ratings_file)

    return products, users, ratings

folder_path = 'cellphones-recommendations'
products, users, ratings = load_data(folder_path)

"""# Data Understanding

Tujuan tahap ini adalah:

- Melihat info awal data.
"""

def dataset_info(df, name):
    print(f"Dataset: {name}")
    print(f"{'='*50}")
    print(f"Shape   : {df.shape}")
    print(f"Columns : {df.columns.tolist()}\n")

    print("nfo:")
    print(df.info())

    print("\nFirst 10 Rows:")
    print(df.head(10))
    print()

dataset_info(products, "Products")

dataset_info(users, "Users")

dataset_info(ratings, "Ratings")

"""# Exploratory Data Analysis (EDA)"""

def describe(df, name):
    print(f"Statistik Deskriptif: {name}")
    print(df.describe())
    print()

describe(products, "Products")

describe(users, "Users")

describe(ratings, "Ratings")

"""1. **Statistik Deskriptif: Products**
  
  * Internal memory berkisar antara 32–512 GB, dengan rata-rata 148 GB.

  * RAM rata-rata sekitar 6.8 GB, minimum 3 GB dan maksimum 12 GB.

  * Main camera dan selfie camera memiliki variasi besar, dengan kamera utama tertinggi mencapai 108 MP.

  * Battery size rata-rata 4320 mAh, menunjukkan sebagian besar ponsel memiliki baterai besar.
  * Screen size umumnya berkisar antara 4.7 hingga 7.6 inci.

  * Price bervariasi cukup besar, dengan rata-rata 628 USD dan maksimum hampir 2000 USD.


2.  **Statistik Deskriptif: Users**

  * Terdapat 99 pengguna, dengan usia antara 21 hingga 61 tahun.

  * Usia rata-rata pengguna adalah sekitar 36 tahun, menunjukkan dominasi usia produktif.


3.  **Statistik Deskriptif: Ratings**

  * Terdapat 990 data rating yang diberikan pengguna terhadap ponsel.

  * Rating berkisar dari 1 hingga 18, dengan rata-rata sekitar 6.7.

  * Distribusi rating menunjukkan nilai tengah di angka 7, dan mayoritas rating berada di rentang 5 hingga 9.

**Visualisasi Fitur**
"""

sns.set_theme(style="whitegrid")
plt.figure(figsize=(10, 5))

# Distribusi Jumlah Ponsel per Brand
brand_counts= products['brand'].value_counts()

sns.countplot(data=products, x='brand', hue='brand', order=brand_counts.index, palette='Set2', legend=False)
plt.title('Distribusi Jumlah Ponsel per Brand', fontsize=14, fontweight='bold')
plt.xlabel("Brand")
plt.ylabel("Jumlah Ponsel")
plt.show()

"""Dari **10** brand yang ada, Samsung memiliki **8** model ponsel paling banyak, disusul Apple dengan **6** model. Sementara itu, Asus, Oppo, Vivo, dan Sony tercatat hanya memiliki **1** model ponsel masing-masing."""

# Mengelompokkan model berdasarkan brand
models_by_brand = products.groupby('brand')['model'].apply(list).to_dict()

# Menghitung jumlah total model
total_models = sum(len(models) for models in models_by_brand.values())
print('Jumlah model ponsel:', total_models)

print("\nDaftar model berdasarkan brand:")
for brand, models in models_by_brand.items():
    print(f"\nBrand: {brand}")
    for model in models:
        print(f"- {model}")

"""Terdapat total **33** model ponsel yang berasal dari seluruh brand yang ada.

"""

# Menghitung jumlah operating system
os_counts = products['operating system'].value_counts()

# Distribusi Sistem Operasi Ponsel
sns.countplot(data=products, x='operating system', palette='Blues', legend=False)
plt.title("Distribusi Sistem Operasi Ponsel")
plt.xlabel("Operating System")
plt.ylabel("Jumlah Ponsel")
plt.show()

"""Grafik tersebut menunjukkan bahwa sebagian besar model ponsel menggunakan sistem operasi **Android**, dengan total sebanyak 27 perangkat. Sementara itu, hanya 6 perangkat yang menggunakan sistem operasi **iOS**."""

def plot_memory_and_ram(data):
    print("Jumlah Internal Memory:\n", data['internal memory'].value_counts(), "\n")
    print("Jumlah RAM:\n", data['RAM'].value_counts(), "\n")
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    # Plot Internal Memory
    sns.countplot(ax=axes[0], data=data, x='internal memory', palette='Blues')
    axes[0].set_title("Distribusi Internal Memory", fontsize=13, fontweight='bold')
    axes[0].set_xlabel("Internal Memory (GB)")
    axes[0].set_ylabel("Jumlah")

    # Plot RAM
    sns.countplot(ax=axes[1], data=data, x='RAM', palette='Purples')
    axes[1].set_title("Distribusi RAM", fontsize=13, fontweight='bold')
    axes[1].set_xlabel("RAM (GB)")
    axes[1].set_ylabel("Jumlah")

    plt.tight_layout()
    plt.show()

plot_memory_and_ram(products)

"""Grafik tersebut menunjukkan sebagian besar perangkat yang tersedia dilengkapi dengan memori internal sebesar **128 GB** sebanyak **20 perangkat**, serta **RAM 8 GB** yang digunakan pada **13 perangkat**.

"""

min_performance = products['performance'].min()
max_performance = products['performance'].max()
print(f"Rentang nilai performance: {min_performance} - {max_performance}\n")

# Memisahkan produk berdasarkan ambang batas performance
performance_high = products[products['performance'] > 5]
performance_low = products[products['performance'] <= 5]

# Menghitung total data untuk masing-masing kategori
total_high = len(performance_high)
total_low = len(performance_low)

# Menampilkan total produk untuk masing-masing kategori
print("Total ponsel dengan performa tinggi:", total_high)
print("Total ponsel dengan performa rendah:", total_low)

# Menyiapkan data untuk visualisasi
performance_summary = pd.DataFrame({
    'Category': ['High', 'Low'],
    'Total': [total_high, total_low]})

# Membuat grafik batang dengan warna menarik
plt.figure(figsize=(8, 5))
barplot = sns.barplot(data=performance_summary, x='Category', y='Total', palette='Blues')

plt.title("Distribusi Kategori Performa", fontsize=14, fontweight='bold')
plt.xlabel("Kategori Performa")
plt.ylabel("Jumlah")
plt.tight_layout()
plt.show()

"""Rentang nilai performa berkisar antara 1,02 hingga 11,0, dengan kategori performa rendah untuk nilai di bawah 5 dan performa tinggi untuk nilai di atas 5. Grafik tersebut memperlihatkan bahwa dari total perangkat, terdapat 23 unit dengan performa tinggi dan 10 unit dengan performa rendah berdasarkan hasil pengujian menggunakan AnTuTu.

"""

# Menampilkan rentang nilai harga
min_price = products['price'].min()
max_price = products['price'].max()
print(f"Rentang harga: {min_price} - {max_price}\n")

# Membuat kategori harga: Entry Level, Mid Level, Flagship
price_bins = [0, 300, 800, max_price + 1]
price_labels = ['Entry Level (0-300 USD)', 'Mid Level (301-800 USD)', 'Flagship (>800 USD)']
products['price_category'] = pd.cut(products['price'], bins=price_bins, labels=price_labels, include_lowest=True)

# Menghitung jumlah ponsel di setiap kategori harga
category_counts = products['price_category'].value_counts().sort_index()
print("Jumlah ponsel per kategori harga:")
print(category_counts)

# Distribusi kategori harga
plt.figure(figsize=(10, 5))
sns.barplot(x=category_counts.index, y=category_counts.values, palette='Purples')
plt.title("Distribusi Kategori Harga Ponsel")
plt.xlabel("Kategori Harga")
plt.ylabel("Jumlah Ponsel")
plt.tight_layout()
plt.show()

"""Dari grafik tersebut, jumlah ponsel berdasarkan kategori harga menunjukkan bahwa terdapat **8** perangkat pada kategori Entry Level (0-300 USD), **16** perangkat pada kategori Mid Level (301-800 USD), dan **9** perangkat pada kategori Flagship dengan harga di atas 800 USD."""

user_review_counts = ratings['user_id'].value_counts()

print("Analisis Review User: ")
print("\nJumlah review per user:")
print(user_review_counts.describe())  # Statistik ringkas (count, mean, std, min, max, dll)

unique_review_counts = user_review_counts.unique()
print(f"\nNilai unik jumlah review per user: {unique_review_counts}")

if len(unique_review_counts) == 1:
    print(f"Semua user melakukan jumlah review yang sama: {unique_review_counts[0]} review per user.")
else:
    print(f"User dengan review terbanyak: {user_review_counts.max()} review")
    print(f"User dengan review paling sedikit: {user_review_counts.min()} review")
    print(f"Rata-rata review per user: {user_review_counts.mean():.2f}")

"""**Analisis Ulasan Pengguna:**

* Setiap pengguna memberikan jumlah ulasan yang sama, yakni sebanyak 10 ulasan.
"""

# Hitung jumlah review untuk tiap tipe ponsel
cellphone_review_counts = ratings['cellphone_id'].value_counts().reset_index()
cellphone_review_counts.columns = ['cellphone_id', 'review_count']

cellphone_reviews = cellphone_review_counts.merge(
    products[['cellphone_id', 'model']],
    on='cellphone_id',
    how='left'
)

min_reviews = cellphone_review_counts['review_count'].min()
max_reviews = cellphone_review_counts['review_count'].max()
avg_reviews = cellphone_review_counts['review_count'].mean()

print("Analisis Review per Tipe Ponsel: ")
print(f"Ponsel dengan review paling sedikit: {min_reviews} review")
print(f"Ponsel dengan review paling banyak: {max_reviews} review")
print(f"Rata-rata jumlah review per ponsel: {avg_reviews:.2f}")

plt.figure(figsize=(15, 7))
sns.barplot(x='model', y='review_count', data=cellphone_reviews.sort_values('review_count', ascending=False),
            palette='PuBu')
plt.title("Distribusi Jumlah Review per Tipe Ponsel (Urut dari yang Terbanyak)")
plt.xlabel("Model Ponsel")
plt.ylabel("Jumlah Review")
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""**Analisis Ulasan Ponsel:**

* Ponsel dengan jumlah ulasan terbanyak adalah **Moto G Play (2021)** dengan **41** ulasan, sementara ponsel dengan ulasan paling sedikit adalah **iPhone SE (2022)** dan **10T**, masing-masing menerima **20** ulasan.
"""

# Hitung distribusi rating
rating_counts = ratings['rating'].value_counts().sort_index()

# Statistik rating
min_rating = ratings['rating'].min()
max_rating = ratings['rating'].max()
mean_rating = ratings['rating'].mean()

print("Analisis Distribusi Rating: ")
print(f"Rating terkecil: {min_rating}")
print(f"Rating terbesar: {max_rating}")
print(f"Rata-rata rating: {mean_rating:.2f}")

# Deteksi kemungkinan outlier rating (nilai di luar rentang umum 1-10)
if max_rating > 10 or min_rating < 1:
    print("Terdapat nilai rating yang mencurigakan (outliers) dalam data.")

# Visualisasi distribusi rating
plt.figure(figsize=(6, 5))
sns.countplot(x='rating', data=ratings, palette='Blues')
plt.title("Distribusi Rating User")
plt.xlabel("Rating")
plt.ylabel("Jumlah Review")
plt.tight_layout()
plt.show()

"""**Analisis Distribusi Rating:**

* Nilai rating berkisar antara 1 hingga 10. Rating yang paling sering muncul adalah nilai 8 dengan **195** kemunculan, sedangkan rating yang paling jarang diberikan adalah nilai 3 dengan **30** kemunculan. Selain itu, terdapat outlier pada nilai rating sebesar 18.
"""

# Hitung frekuensi kemunculan setiap usia dan tampilkan secara terurut
age_counts = users['age'].value_counts().sort_index()

# Tampilkan rentang usia pengguna
min_age = users['age'].min()
max_age = users['age'].max()
most_common_age = age_counts.idxmax()
most_common_age_count = age_counts.max()

print("Analisis Usia Pengguna: ")
print(f"Usia termuda: {min_age}")
print(f"Usia tertua: {max_age}")
print(f"Usia yang paling banyak muncul: {most_common_age} (sebanyak {most_common_age_count} pengguna)")

# Visualisasi distribusi usia
plt.figure(figsize=(10, 5))
sns.countplot(data=users, x='age', palette='Blues')
plt.title("Distribusi Usia Pengguna")
plt.xlabel("Usia")
plt.ylabel("Jumlah Pengguna")
plt.tight_layout()
plt.show()

"""Grafik menunjukkan mayoritas pengguna berusia 25–35 tahun, dengan puncak pada usia 25 (12 pengguna). Usia termuda adalah 21 dan tertua 61. Ini menunjukkan dominasi pengguna usia muda, yang penting dipertimbangkan dalam sistem rekomendasi."""

# Hitung jumlah setiap kategori gender dan tampilkan
gender_counts = users['gender'].value_counts().sort_index()
print("Analisis Gender Pengguna: ")

if '-Select Gender-' in gender_counts.index:
    print("Terdapat data invalid berupa pilihan '-Select Gender-' yang perlu dibersihkan.")

plt.figure(figsize=(5, 3))
sns.countplot(data=users, x='gender', palette='Blues')
plt.title("Distribusi Gender Pengguna")
plt.xlabel("Gender")
plt.ylabel("Jumlah Pengguna")
plt.tight_layout()
plt.show()

"""Grafik menunjukkan distribusi gender pengguna didominasi oleh **laki-laki (50 pengguna)** dan **perempuan (45 pengguna)**. Terdapat juga beberapa entri tidak valid atau kosong **(label "-Select Gender-")** sebanyak **4 pengguna**. Data ini penting untuk memastikan sistem rekomendasi bersifat inklusif terhadap seluruh gender."""

# Hitung jumlah kemunculan tiap jenis pekerjaan (case insensitive)
occupation_counts = users['occupation'].str.lower().value_counts().sort_index()
print("Analisis Pekerjaan Pengguna: ")
print(f"Jumlah kategori pekerjaan unik: {len(occupation_counts)}")
print("Frekuensi pekerjaan pengguna:")
print(occupation_counts)

# Deteksi kesalahan penulisan umum pada pekerjaan
if 'healthare' in occupation_counts.index:
    print("\nDitemukan kesalahan penulisan pada 'healthare', yang benar adalah 'healthcare'.")

# Identifikasi pekerjaan yang bisa digabungkan untuk analisis yang lebih rapi
if 'information technology' in occupation_counts.index and 'it' in occupation_counts.index:
    print("Pekerjaan dengan kategori 'information technology' dan 'it' dapat digabungkan menjadi satu kelompok untuk mempermudah analisis.")

"""Berdasarkan data pekerjaan pengguna:

* Terdapat 45 kategori pekerjaan unik.

* Pekerjaan terbanyak adalah manager sebanyak 18 pengguna, diikuti oleh information technology (12 pengguna) dan it (6 pengguna).

* Ditemukan duplikasi makna pekerjaan, seperti information technology dan it, yang sebaiknya digabungkan untuk analisis lebih akurat.

* Terdapat kesalahan penulisan pada healthare, yang seharusnya healthcare.

# Data Preparation

Pada tahap ini dilakukan:

1. **Merged all datasets**
"""

ratings_data = pd.merge(ratings, products, on='cellphone_id')
merged_data = pd.merge(ratings_data, users, on='user_id')

"""2. **Cek dan Hapus Missing Values**"""

def check_and_drop_missing(data):
    # Periksa jumlah data yang hilang (missing value) di setiap kolom
    missing_values = data.isnull().sum()
    print("Jumlah data yang hilang di setiap kolom:")
    print(missing_values)

    # Tampilkan detail kolom dan baris yang memiliki missing value, jika ada
    if missing_values.any():
        print("\nTerdapat kolom yang mengandung nilai yang hilang.")
        print(data[data.isnull().any(axis=1)])
        cleaned_data = data.dropna()
        print("\nDataset setelah dihapus baris yang mengandung nilai yang hilang.")
        return cleaned_data
    else:
        print("\nDataset tidak mengandung nilai yang hilang.")
        return data

merged_data = check_and_drop_missing(merged_data)

"""Terdapat 10 nilai kosong pada kolom `occupation`, dan langsung dilakukan penanganan dengan cara di hapus baris yang mengandung nilai kosong tersebut.

3. **Cek dan Hapus Data Duplikat**
"""

def check_and_drop_duplicates(data):

    duplicate_count = data.duplicated().sum()
    print(f"Jumlah data duplikat: {duplicate_count}")

    if duplicate_count > 0:
        print("\nTerdapat data duplikat:")
        print(data[data.duplicated()])
        cleaned_data = data.drop_duplicates()
        print("\nDataset setelah dihapus data duplikat.")
        return cleaned_data
    else:
        print("\nDataset tidak mengandung data duplikat.")
        return data

merged_data = check_and_drop_duplicates(merged_data)

"""Tidak terdapat nilai terduplikasi

4. **Cek dan Hapus Nilai Invalid**
"""

def check_invalid(data):
    # Periksa jumlah data dengan entri gender tidak valid "-Select Gender-"
    invalid_gender_count = data[data['gender'] == "-Select Gender-"].shape[0]
    print(f"Jumlah data gender invalid (-Select Gender-): {invalid_gender_count}")

    if invalid_gender_count > 0:
        print("\nData gender '-Select Gender-':")
        print(data[data['gender'] == "-Select Gender-"])
        cleaned_data = data[data['gender'] != "-Select Gender-"]
        print("\nDataset setelah dihapus entri dengan gender '-Select Gender-'")
        return cleaned_data
    else:
        print("\nTidak ditemukan entri dengan gender '-Select Gender-' dalam dataset.")
        return data

check_invalid(merged_data)

"""Fungsi ini digunakan untuk memeriksa dan menghapus entri data yang memiliki nilai tidak valid pada kolom gender, khususnya nilai "-Select Gender-" yang merupakan placeholder dan bukan kategori gender sebenarnya. Tahapannya:

1. Menghitung jumlah entri dengan gender "-Select Gender-".

2. Menampilkan entri-entri tersebut (jika ada), agar pengguna dapat melihat data yang bermasalah.

3. Menghapus entri yang memiliki gender tidak valid dari dataset agar hasil analisis tidak bias atau keliru.

Fungsi ini mengembalikan dataset yang telah dibersihkan dari entri gender tidak valid.

5. **Hapus Outlier dan Memperbaiki Typo Penulisan**
"""

def cleaning_data(data):
    # Drop rows with rating == 18
    cleaned_data = data[data['rating'] != 18]
    print("Data dengan rating 18 telah dihapus.")

    # Replace 'healthare' with 'healthcare'
    cleaned_data['occupation'] = cleaned_data['occupation'].replace('healthare', 'healthcare')
    print("Data 'healthare' telah diganti menjadi 'healthcare'.")

    # Replace 'it' with 'information technology'
    cleaned_data['occupation'] = cleaned_data['occupation'].replace('it', 'information technology')
    print("Data 'it' telah diganti menjadi 'information technology'.")

    # Convert all occupation values to lowercase
    cleaned_data['occupation'] = cleaned_data['occupation'].str.lower()
    print("Seluruh nilai pada kolom 'occupation' telah diubah menjadi lowercase.")

    return cleaned_data

merged_data = cleaning_data(merged_data)

"""Fungsi ini digunakan untuk membersihkan data dari nilai-nilai yang tidak valid atau tidak konsisten, khususnya pada kolom rating dan occupation. Berikut tahapan pembersihannya:

1. Menghapus data dengan rating = 18, karena nilai ini tidak valid (rating seharusnya berada pada rentang 1–10).

2. Mengoreksi kesalahan penulisan pada kolom occupation, seperti:

3. Mengganti 'healthare' menjadi 'healthcare'.

4. Mengganti 'it' menjadi 'information technology'.

5. Mengubah semua nilai pada occupation menjadi huruf kecil (lowercase) untuk menjaga konsistensi data.
"""

merged_data.info()

"""6. **Membersihkan dan menyiapkan data ponsel untuk analisis lebih lanjut.**"""

def prepare_data(df):
    print("Data Preparation: ")

    unique_df = df.drop_duplicates(subset='cellphone_id').reset_index(drop=True)
    print(f"Total entri unik berdasarkan 'cellphone_id': {len(unique_df)}")

    selected_columns = ['cellphone_id', 'brand', 'model', 'operating system']
    prepared_df = unique_df[selected_columns].copy()
    prepared_df.columns = ['cellphone_id', 'brand', 'model', 'operating_system']

    print("Kolom yang dipilih berhasil diproses dan disusun ulang.")
    print(f"Dimensi DataFrame baru: {prepared_df.shape[0]} baris x {prepared_df.shape[1]} kolom")

    return prepared_df

final_df = prepare_data(merged_data)

"""Fungsi ini digunakan untuk membersihkan dan menyiapkan data ponsel sebelum digunakan dalam analisis atau pemodelan. Tahapan yang dilakukan:

1. Menghapus duplikat berdasarkan cellphone_id agar setiap ponsel hanya muncul satu kali.

2. Memilih kolom penting: cellphone_id, brand, model, dan operating system.

3. Mengganti nama kolom agar seragam (misalnya, mengganti operating system menjadi operating_system).

4. Mengembalikan DataFrame baru yang sudah bersih dan siap dipakai.

7. **Split Data Ratings**
"""

# Split Data Ratings
train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)

"""Split dataset ratings untuk kebutuhan evaluasi model CF"""

print(final_df)

"""# Modeling and Result

1. Content Based Filtering (CBF)
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Fit dan transform TF-IDF pada data brand
brand_tfidf = tf.fit_transform(final_df['brand'])

# Ambil nama fitur
feature_names = tf.get_feature_names_out()
print("Fitur nama: ", feature_names)

# Tampilkan vektor hasil transformasi
print("\nTF-IDF Matrix:")
print(brand_tfidf.toarray())

"""Kode ini mengubah teks kolom brand menjadi representasi numerik menggunakan TF-IDF. Hasilnya adalah matriks yang menunjukkan bobot setiap kata unik dalam data brand."""

# Konversi ke DataFrame dengan index model
tfidf_df = pd.DataFrame(
    brand_tfidf.todense(),
    columns=feature_names,
    index=final_df['model']
)

# Sampling baris dan kolom secara acak (misal 10x10)
sampled_df = tfidf_df.sample(n=10, axis=0, random_state=42).sample(n=10, axis=1, random_state=42)

# Tampilkan hasil sampel
print(f"Matriks TF-IDF (sampel 10 x 10):")
print(sampled_df)

"""Kode ini mengubah matriks TF-IDF menjadi DataFrame dengan indeks nama model. Kemudian, mengambil sampel acak 10 baris dan 10 kolom untuk menampilkan sebagian kecil dari matriks TF-IDF secara lebih ringkas."""

# Menghitung cosine similarity dari matriks TF-IDF
cosine_sim = cosine_similarity(brand_tfidf)
print("Cosine similarity matrix berhasil dihitung.")

# Membuat DataFrame dari cosine similarity dengan index dan columns yang sama (model)
cosine_sim_df = pd.DataFrame(cosine_sim, index=final_df['model'], columns=final_df['model'])
print(f"Shape of similarity matrix: {cosine_sim_df.shape}")

# Sampling baris dan kolom cosine similarity secara acak (misal 10x10)
sampled_cosine_sim_df = cosine_sim_df.sample(n=10, axis=0, random_state=42).sample(n=10, axis=1, random_state=42)
print("\nMatriks kesamaan cosine similarity (sampel 10 x 10):")
print(sampled_cosine_sim_df)

"""Kode ini menghitung cosine similarity antar model berdasarkan fitur TF-IDF brand, lalu menyimpannya dalam DataFrame berindeks nama model. Sampel 10x10 diambil untuk menampilkan sebagian kecil matriks similarity secara ringkas."""

def item_cbf_recomendation(target_model, similarity_df, metadata, top_n=5):

    if target_model not in similarity_df.columns:
        raise ValueError(f"Model '{target_model}' tidak ditemukan dalam similarity matrix.")

    # Ambil similarity score untuk model target
    scores = similarity_df[target_model]

    # Urutkan model berdasarkan skor similarity, dari terbesar ke kecil, kecuali model target sendiri
    similar_models = scores.drop(target_model).sort_values(ascending=False).head(top_n).index

    # Ambil metadata model-model yang direkomendasikan
    recommendations = metadata[metadata['model'].isin(similar_models)].copy()

    # Hapus kolom 'cellphone_id' jika ada
    if 'cellphone_id' in recommendations.columns:
        recommendations = recommendations.drop(columns=['cellphone_id'])

    # Tambahkan kolom skor similarity supaya bisa dilihat seberapa mirip
    recommendations['similarity_score'] = recommendations['model'].map(scores)

    # Urutkan hasil berdasarkan similarity score tertinggi
    recommendations = recommendations.sort_values(by='similarity_score', ascending=False)

    return recommendations.reset_index(drop=True)

"""Fungsi ini mencari rekomendasi model ponsel yang paling mirip dengan `target_model` berdasarkan matriks similarity.

* Input: nama model target, matriks similarity antar model, metadata model, dan jumlah rekomendasi.
* Output: DataFrame rekomendasi model paling mirip beserta metadata dan skor similarity.
* Fungsi mengurutkan model berdasarkan kemiripan tertinggi, menghilangkan model target sendiri, dan menghapus kolom `cellphone_id` jika ada.

"""

target_model = 'iPhone 13 Pro'

# Panggil fungsi rekomendasi
recommendations = item_cbf_recomendation(target_model, cosine_sim_df, final_df, top_n=5)

# Tampilkan hasil rekomendasi
print("Rekomendasi model mirip dengan:", target_model)
print(recommendations)

"""Rekomendasi model yang dihasilkan menunjukkan 5 ponsel yang paling mirip dengan **iPhone 13 Pro** berdasarkan kemiripan fitur brand dan model (TF-IDF + cosine similarity).

* Semua rekomendasi berasal dari brand **Apple** dan menggunakan **operating system iOS**, sama seperti model target.
* Skor similarity-nya sama yaitu **1.0**, menandakan kemiripan yang sangat tinggi dalam fitur brand dan model.
* Rekomendasi ini membantu pengguna menemukan model ponsel Apple lain yang secara fitur brand dan nama sangat mirip dengan iPhone 13 Pro, sehingga kemungkinan memiliki karakteristik serupa.

2. Collaborative Filtering (CF)
"""

print(ratings['user_id'].unique())

# Buat user-item matrix (baris: user, kolom: item)
user_item_matrix = ratings.pivot_table(
    index='user_id',
    columns='cellphone_id',
    values='rating'
).fillna(0)

# Ubah ke bentuk sparse untuk efisiensi
user_item_sparse = csr_matrix(user_item_matrix)

# Hitung Similaritas Antar User
user_sim = cosine_similarity(user_item_sparse)

# DataFrame untuk user-user similarity
user_sim_df = pd.DataFrame(
    user_sim,
    index=user_item_matrix.index,
    columns=user_item_matrix.index
)

print("User-user similarity matrix berhasil dihitung.")

"""Kode diatas membuat matriks user-item dari rating, lalu hitung kemiripan antar user dengan cosine similarity. Hasilnya matriks kemiripan user untuk rekomendasi berbasis user.

"""

# Fungsi Rekomendasi Berdasarankan User-Based
def user_cf_recommendation(target_user_id, similarity_df, ratings_df, metadata_df, top_n=5):
    if target_user_id not in similarity_df.index:
        raise ValueError(f"User ID '{target_user_id}' tidak ditemukan dalam similarity matrix.")

    # Ambil skor similarity user target ke user lain
    sim_scores = similarity_df.loc[target_user_id]

    # Ambil user-user yang paling mirip (kecuali dirinya sendiri)
    similar_users = sim_scores.drop(target_user_id).sort_values(ascending=False).head(5).index

    # Ambil semua rating dari user-user yang mirip
    similar_users_ratings = ratings_df[ratings_df['user_id'].isin(similar_users)]

    # Hilangkan item yang sudah dirating oleh target user
    rated_items = ratings_df[ratings_df['user_id'] == target_user_id]['cellphone_id'].unique()
    unrated_by_target = similar_users_ratings[~similar_users_ratings['cellphone_id'].isin(rated_items)]

    # Hitung skor rata-rata rating item dari user yang mirip
    recommended = (
        unrated_by_target
        .groupby('cellphone_id')['rating']
        .mean()
        .sort_values(ascending=False)
        .head(top_n)
    )

    # Gabungkan dengan metadata
    result = metadata_df[metadata_df['cellphone_id'].isin(recommended.index)].copy()
    result['predicted_rating'] = result['cellphone_id'].map(recommended)

    return result.sort_values(by='predicted_rating', ascending=False).reset_index(drop=True)

# Inference
target_user = 10
recommendations_user = user_cf_recommendation(target_user, user_sim_df, ratings, final_df, top_n=5)

print(f"Rekomendasi berdasarkan User-Based CF untuk user_id {target_user}:")
print(recommendations_user)

"""Output menampilkan daftar 5 ponsel yang direkomendasikan untuk user dengan `user_id` 10 berdasarkan preferensi pengguna lain yang mirip dengannya. Kolom `predicted_rating` menunjukkan rata-rata skor rating yang diperkirakan dari pengguna serupa, menandakan seberapa cocok ponsel tersebut untuk user target.

Misalnya, ponsel "Pixel 6 Pro" dari Google memiliki skor tertinggi 10.0, jadi direkomendasikan paling utama untuk user ini.

# Evaluation

2. CF Evaluation
"""

def precision_at_k(recommended_items, relevant_items, k=5):

    recommended_k = recommended_items[:k]
    relevant_set = set(relevant_items)
    hits = sum([1 for item in recommended_k if item in relevant_set])
    return hits / k

"""Fungsi ini menghitung **Precision\@K**, yaitu seberapa banyak dari *top K* item rekomendasi yang benar-benar relevan. Nilai Precision\@K berkisar antara 0 sampai 1, semakin tinggi berarti rekomendasi semakin tepat.

"""

def recall_at_k(recommended_items, relevant_items, k=5):

    recommended_k = recommended_items[:k]
    relevant_set = set(relevant_items)
    if len(relevant_set) == 0:
        return 0.0
    hits = sum([1 for item in recommended_k if item in relevant_set])
    return hits / len(relevant_set)

"""Fungsi ini menghitung **Recall\@K**, yaitu proporsi item relevan yang berhasil ditemukan dalam *top K* item rekomendasi dari semua item relevan yang ada. Nilai Recall\@K antara 0 sampai 1, semakin tinggi berarti sistem rekomendasi semakin lengkap menangkap item relevan. Jika tidak ada item relevan, hasilnya 0.0."""

# Evaluasi User-Based CF
test_users = test_ratings['user_id'].unique()
results_cf = []
top_n = 5

for user in test_users:
    # Item yang user rating di test set (ground truth relevan)
    relevant_items = test_ratings[test_ratings['user_id'] == user]['cellphone_id'].unique().tolist()

    if len(relevant_items) == 0:
        continue

    try:
        recommended_cf_df = user_cf_recommendation(user, user_sim_df, train_ratings, final_df, top_n)
        recommended_cf = recommended_cf_df['cellphone_id'].tolist()
    except Exception:
        recommended_cf = []

    prec_cf = precision_at_k(recommended_cf, relevant_items, top_n)
    rec_cf = recall_at_k(recommended_cf, relevant_items, top_n)

    results_cf.append({
        'user_id': user,
        'precision_cf': prec_cf,
        'recall_cf': rec_cf
    })

eval_cf_df = pd.DataFrame(results_cf)
print("Hasil Evaluasi User-Based CF per user:")
print(eval_cf_df.head())

print("\nRata-rata Precision@5 untuk CF:")
print(eval_cf_df['precision_cf'].mean())

print("\nRata-rata Recall@5 untuk CF:")
print(eval_cf_df['recall_cf'].mean())

"""* **Tabel hasil evaluasi per user** menampilkan nilai Precision\@5 dan Recall\@5 untuk beberapa user contoh.

  * *Precision\@5* menunjukkan proporsi rekomendasi yang benar-benar relevan di antara 5 item teratas yang direkomendasikan untuk tiap user.
  * *Recall\@5* menunjukkan proporsi item relevan yang berhasil ditemukan dalam 5 rekomendasi.

* **Rata-rata Precision\@5 sekitar 0.175** berarti sekitar 17.5% dari rekomendasi top 5 secara keseluruhan memang relevan untuk pengguna. Ini menunjukkan ada ruang perbaikan supaya rekomendasi lebih tepat sasaran.

* **Rata-rata Recall\@5 sekitar 0.43** berarti sistem berhasil menangkap sekitar 43% dari semua item relevan pengguna di dalam 5 rekomendasi teratas. Ini cukup baik untuk cakupan rekomendasi, tapi bisa ditingkatkan lagi agar lebih banyak item relevan masuk rekomendasi.

Secara keseluruhan, evaluasi ini memberikan gambaran performa sistem User-Based CF dalam merekomendasikan produk yang sesuai dengan preferensi pengguna berdasarkan rating historis.
"""

# Tentukan 1 user_id dari test set
sample_user_id = 1

# Ambil item yang relevan (yang dirating oleh user ini di test set)
relevant_items = test_ratings[test_ratings['user_id'] == sample_user_id]['cellphone_id'].unique().tolist()

# Skip jika user tidak punya data di test
if len(relevant_items) == 0:
    print(f"Tidak ada data test untuk user_id {sample_user_id}.")
else:
    # Ambil 5 rekomendasi teratas dari model User-Based CF
    try:
        recommended_cf_df = user_cf_recommendation(sample_user_id, user_sim_df, train_ratings, final_df, top_n=5)
        recommended_cf = recommended_cf_df['cellphone_id'].tolist()
    except Exception as e:
        print(f"Terjadi error saat rekomendasi untuk user_id {sample_user_id}: {e}")
        recommended_cf = []
        recommended_cf_df = pd.DataFrame()

    # Hitung Precision@5 dan Recall@5
    precision = precision_at_k(recommended_cf, relevant_items, k=5)
    recall = recall_at_k(recommended_cf, relevant_items, k=5)

    # Tampilkan hasil evaluasi
    print(f"Hasil Evaluasi untuk user_id {sample_user_id}:")
    print(f"  Relevant Items (ground truth): {relevant_items}")
    print(f"  Recommended Items: {recommended_cf}")
    print(f"  Precision@5: {precision:.2f}")
    print(f"  Recall@5: {recall:.2f}\n")

    # Tampilkan metadata rekomendasi
    print(f"Detail Rekomendasi untuk user_id {sample_user_id}:")
    print(recommended_cf_df[['model', 'brand', 'predicted_rating']])

"""Kode di atas berfungsi untuk **mengevaluasi performa sistem rekomendasi User-Based Collaborative Filtering (CF)** dengan menghitung metrik **Precision\@5** dan **Recall\@5** untuk seorang user (`user_id = 1`).

Hasil evaluasi menunjukkan bahwa:

* Sistem berhasil merekomendasikan **1 item yang relevan dari 5 rekomendasi** (Precision\@5 = 0.20).
* **Seluruh item relevan berhasil ditemukan** dalam rekomendasi (Recall\@5 = 1.00).

Ini menunjukkan bahwa sistem cukup baik dalam **menjangkau preferensi user**, namun perlu ditingkatkan untuk **mengurangi item yang tidak relevan** dalam daftar rekomendasi.

# Summary and Insights

Berikut adalah **Summary and Insights** yang mencakup kedua metode — **Content-Based Filtering (CBF)** dan **Collaborative Filtering (CF)** — serta hasil evaluasinya secara ringkas dan relevan dengan proyek sistem rekomendasi smartphone:

---

### **Summary and Insights**

**Content-Based Filtering (CBF):**
CBF merekomendasikan smartphone berdasarkan kemiripan atribut konten, seperti model, merek, dan fitur-fitur lainnya. Model ini mampu memberikan rekomendasi yang personal karena mempertimbangkan item yang sebelumnya disukai oleh pengguna.

* Pada evaluasi, model CBF mencapai **Precision\@3 sebesar 0.67**, yang berarti sebagian besar dari 3 item teratas yang direkomendasikan adalah relevan bagi pengguna.
* CBF cocok digunakan saat informasi pengguna masih terbatas (cold start) karena hanya bergantung pada data item.

**User-Based Collaborative Filtering (CF):**
Model CF merekomendasikan item berdasarkan preferensi pengguna lain yang memiliki kemiripan pola rating. Model ini unggul dalam menangkap minat kolektif dan mampu merekomendasikan item baru yang belum pernah dinilai pengguna.

* Dari evaluasi terhadap beberapa pengguna, **Precision\@5 rata-rata sebesar 0.175** dan **Recall\@5 sebesar 0.43**.
* Untuk contoh pengguna `user_id = 1`, model berhasil memberikan rekomendasi dengan **Precision\@5 = 0.20** dan **Recall\@5 = 1.00**, yang berarti seluruh item relevan berhasil direkomendasikan.

**Insights:**

* **CBF unggul dalam ketepatan rekomendasi (precision tinggi)** untuk item yang mirip dengan yang pernah disukai pengguna.
* **CF unggul dalam jangkauan rekomendasi (recall tinggi)** dan mampu menemukan item baru yang belum pernah dilihat pengguna.
* **Kedua metode saling melengkapi**: CBF cocok untuk personalisasi, sementara CF memanfaatkan informasi dari komunitas pengguna.
* Evaluasi selanjutnya disarankan menggunakan metrik tambahan seperti **F1-Score**, **MAE**, atau **RMSE** agar performa model dapat dibandingkan secara lebih komprehensif.
* **Hybrid approach** dapat dipertimbangkan untuk meningkatkan kualitas rekomendasi dengan menggabungkan kelebihan CBF dan CF.
"""